Task 1: Monitor all the server disk space and informed to Nitin and Rajeev Sir to delete the space
       Used commands: df -Th  -- To check the disk space
                      du -sh * | grep G -- check the directory space 

Task 2:Monitoring the  Service running status
Task 3:Creating Failed job/process and batch job execution count
Task 4:Monitoring the Memory utilization from report
Task 5:Monitoring Observium for Load avg,System I/O of all servers
Task 6:Parser deployment on EMP QA(101.53.142.42)
       1.Jenkins run on : 172.16.0.68:8080 --EPM-QA,NEWRE 
       2.download the parser from project build no 
       3.copy to 101.53.142.42:scp -r EPM-parser-1.12-SNAPSHOT.jar root@101.53.142.42:/mnt
       4.After transfer the jar to the server, type the "parser_deploy"
       5.parser_deploy --In the mnt folder
       6.username : root
       7. For deployment type 1 and 2 respectfully

Task 7:Depoly Solar UI on wind3 server(205.147.98.133)
       -- Build the Jenkins jobs on http://172.16.0.66:8082
       -- Pull the image on portainer (Docker Gamesha VPN) and update it
             --spfs-prod image
       -- Do Sanity check for https://restaging.50hertz.in/  and after that confirmed.

Task 8: On wind3 server(205.147.98.133)
       -- Create an user and give the password for FTP 
        e.g.
        # useradd kkr -s /sbin/nologin
        # passwd kkr
        -- Giving permissions to the Folder as per request
        
        e.g. Here below permission(read) has been given to kkr user for SEMS folder 

         setfacl -m u:kkr:rx /home/wind/
         setfacl -m u:kkr:rx /home/wind/SOLAR/
         setfacl -m u:kkr:rx /home/wind/SOLAR/SEMS/

         How to konw the permission is given proper

         getfacl /SEMS

         -- After this work has been done update the documentation and send the email to team

 Task 9:wind3 server(205.147.98.133) ---Update the properties file details as per the request

         path: /home/PROPERTY_FILES/SOLAR
         -- Similary for WIND properties files
         -- using vi/vim editor edit the files

 Task 10: On AWS FTP server (15.207.32.135)
        -- Create an user and give the password for FTP 
        e.g.
        # useradd kkr -s /sbin/nologin
        # passwd kkr
        -- Giving permissions to the Folder as per request
        
        e.g. Here below permission(read) has been given to kkr user for SEMS folder 

         setfacl -m u:kkr:rx /home/wind/
         setfacl -m u:kkr:rx /home/wind/SOLAR/
         setfacl -m u:kkr:rx /home/wind/SOLAR/SEMS/

         How to konw the permission is given proper

         getfacl /SEMS
     -- After this work has been done update the documentation and send the email to team


 Task 11: On EPM Production Server(13.127.156.228)

        Restart the SCHEDULAR 4 process
        -- Check the process 
         ps aux | grep SCH
         -- Restart the Process, first kill the process and run the script for running the process
         e.g.kill -9 26685; sh /home/www_epm/prod/bin/EPM-engine4.sh

         Another way of restart the SCHEDULAR 4

         e.g. kill -9 26685;nohup /var/lib/java/jdk1.8.0_211/bin/java -Duser.timezone=IST -DAsyncLogger.ThreadNameStrategy=UNCACHED -Dserver.mode=prod -Xmx2g -DPROCESSNAME=SCHEDULAR-4 -DEPM_HOME=/home/www_epm/prod -Dcom.sel.product=epm -Dspring.batch.job.enabled=false -Dorg.quartz.scheduler.instanceName=SCHEDULAR-4 -XX:+HeapDumpOnOutOfMemoryError -jar /home/www_epm/prod/lib/EPM-parser-1.12-SNAPSHOT_02032021.jar&
 
 Task 12: run the script for fetching the data (3.7.173.57--bids)
   3.7.173.57

Task: Understanding the OPC_QA Data fething through the Python script
     
     --taglist -- we are collecting the taglist 
     
     Process:
     On the client machine (path:D/Manikaran_QCA)
     -- Type on cmd on above path to list out the file
        #opc -q  (To list out the files on this folder)
        #opc CoDeSys.OCP.DA -l
        #opc CoDeSys.OCP.DA -f

        How to update the file 
        1. In this path: scada_producer.py file is present
        Now we can create another script which is copied from scada_producer.py file
        2.Update the the function on python script (sendOutTopPC(body,logger)) on both the file
        3.As we create twoscript from one, we need to remove the one method form it.
        4.add mongoid -- to get the OPC data
        5.note: bestway to take the backup for script 

        Working on Script:

        -- update both the script
        -- change the sendOutTopNew method of ip
        --create "fetch.bat"
        -- create two copy of this script for run the two python script
        -- After that run two fetch.bat script for get the data into kafka server        
        e.g. Check the nvkn.50hertz.in site that data is coming or not

Task: change the config file and restart the job on portainer
        /home/PROPERTY_FILES/SOLAR-- On scadaconfig.properties

        Restart the job 




  Task 12: User system support 
        -- Install Java using zip file 
         Setting the class path:
               [root@files ~]# update-alternatives --config java

         There is 1 program that provides 'java'.

  Selection    Command
-----------------------------------------------
*+ 1           /opt/jdk1.8.0_211/bin/java -- copy the path

[root@files ~]# echo "JAVA_HOME=/opt/jdk1.8.0_211/bin/java" >> .bash_profile 
[root@files ~]# source .bash_profile 
[root@files ~]# echo $JAVA_HOME
/opt/jdk1.8.0_211/bin/java

--- Set the class path of maven
[root@files ~]# echo "M2_HOME=/opt/apache-maven-3.5.4" >> .bash_profile 
                echo "M2_HOME=/opt/apache-maven" >> .bash_profile

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 -- Install MySQL 5.7 on centos 7 
----------------------------

Step 1 – Enable MySQL Repository
#yum localinstall https://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm

First of all, You need to enable MySQL 5.7 community release yum repository on your system. 
The rpm packages for yum repository configuration are available on MySQL official website. 

Step 2 – Install MySQL 5.7 Server
Now, install MySQL 5.7 community server using following commands as per your operating system version.

#yum install mysql-community-server

The above command will install MySQL community server will other dependencies on your system. 
During the installation process of packages, a temporary password is created and logs to MySQL log files. 
Use the following command to find your temporary MySQL password.

Get Temporary root Password:

#grep 'A temporary password' /var/log/mysqld.log |tail -1

2021-02-10T09:25:27.880705Z 1 [Note] A temporary password is generated for root@localhost: l*aFHo,uG8>X

#3. Start MySQL Service

After installing rpms use following command to start MySQL Service.

#service mysqld start

#4. Initial MySQL Configuration

Execute mysql_secure_installation script and follow the wizard. It will prompt for root password. 
Use the temporary root password got in above step.

# /usr/bin/mysql_secure_installation

Securing the MySQL server deployment.

Enter password for user root: 

The existing password for the user account root has expired. Please set a new password.

New password: 

Re-enter new password: 
The 'validate_password' plugin is installed on the server.
The subsequent steps will run with the existing configuration
of the plugin.
Using existing password for root.


--> After use the password, skip the other steps



Step – Login to MySQL 

Congratulations! You have successfully installed MySQL 5.7.

To check the MYSQL Install --Login to mysql as below command:

#mysql -h localhost -u root -p 

Step 6 – Check MySQL Version

verify the mysql version:
# mysql -V

output:
mysql  Ver 14.14 Distrib 5.7.33, for Linux (x86_64) using  EditLine wrapper


Refer the below link:
https://phoenixnap.com/kb/access-denied-for-user-root-localhost

Upgrade the mongodb version: mongo 3.2 to 4.3 version

systemctl stop mongod
yum erase $(rpm -qa | grep mongodb-enterprise)
yum erase $(rpm -qa | grep mongodb-org)
cd /etc/yum.repos.d/
ls
rm -rf mongodb-org.repo mongodb.repo
vi /etc/yum.repos.d/mongodb.repo
yum -y install mongodb-org
systemctl enable --now mongod
systemctl status mongod


.513.126.148.5
EPM-PROD AWS
########################################################


OPC DA : 
#############

Working On OPC_DA

1. Connect to Client system using anydesk

Case 1: For checking the logs and cmd line for data is updating or not
    -- Check the log file
    -- Update the python(producer) script for read the log
    -- do uncomment the log function
    -- Now run the fetch.bat file on cmd for check the log
    -- If it is shows good, then it is working file

Case 2: If it is not working file
    -- Restart the client machine
    -- again do check the all process on case 1
Case 3: Stop the Schedule task on Client System
    -- Another way to start the OPC DA data 
    -- First check the log or rename as backup log
    -- Goto Control Pannel -- Adminstrative--schedular task
    -- Schedule task -- Manikaran -- right click -- end
                                  -- right click -- disable

    -- Now task has been disable
    -- Now Goto D drive where Manikaran folder 
    -- Run the fetch.bat script and see the status of script
    -- If data is showing good, then it has been successful
    -- Now goto Control Pannel -- Adminstrative--schedular task and make it enable


    OPC UA:
     Login to sever: rdesktop 13.232.251.4 -g 1300*600

     Process:
     1.we will create channel and device by the given credential by client
     2. After creating the Channel, we will get the tags from client 
     3. Now we will create a data logger
         Right click the Data Logger -> create new group
         1. Fill the general Properties , e.g. Name: Charanka_A2_INV3, Update rate: 60 seconds
                                               Store and Forward enabled, Maximum storage size:100 MB
                                               Data source Properties: DNS: charanka, User Name: charanka, Password, Login Time: 1000 seconds
                                               Batch Identifier: Upate rate: 60 seconds
        2. Go to Data Map tab
           -- Browser-- the tags and add it
           -- create new database or append it if exsit the data base e.g Charanka_A2

       3. Go to Triggers tab
           set the triger and save it.

    It will working now.

    4. In this way we store the data OPC UA into our database 

    Note:
    Some times data is not updated into our mysql database

    So select the data logger and on map tab -- bro


     

Adding to MongoDB 
######################

    {"display_name":"Khirsara-Adani"}    "status":true, 

Restart NVKN(E2E) connect:
############################

1. Login to the server 
    NEWRE_KAFKA_C1:164.52.195.22

2. check the process 

ps aux | grep connecter-standalone

3. Kill the process

kill -9 <pid>

4.Login to kafka user

#sudo su kafka

5. Remove connect.offsets file on /tmp

cd /tmp;
rm -rf connct.offsets
6. Go to the kafka-live directory

#cd /home/kafka/kafka-live/
#nohup bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties>connect-nohup.out &

7. check the logs on 
 #cd logs
 # tail -f connector.log


8. Restart the bids:

 1. Login to the server  Bids

 ssh admin@3.7.173.57
 2. go the root
 # sudo su
 3.login to the mpl user
 # su mpl

 4. go the web folder
 
 #cd /home/mpl/web
 5. restart the process
 #/usr/bin/perl utils/process-reports&

 6. check the process 

 ps aux | grep process

9.Check the fathegad data is updating or not:

mysql -u root -p
Admin@32121

use kepex;
mysql> select _TIMESTAMP,_QUALITY,count(0) from eden where _TIMESTAMP like '2021-10-02%'  group by _TIMESTAMP,_QUALITY order by _TIMESTAMP;

32121

9100036760


10. How to copy file to remote server in EC2 instance

scp -i "docker2key.pem" first_playbook.yml ec2-user@ec2-3-87-62-236.compute-1.amazonaws.com:/tmp/



11. Docker visualizer for see the docker swarm nodes

docker run -it -d -p 9090:9090 -v /var/run/docker.sock:/var/run/docker.sock dockersamples/visualizer


VERSION=v0.36.0 # use the latest release version from https://github.com/google/cadvisor/releases
sudo docker run \
  --volume=/:/rootfs:ro \
  --volume=/var/run:/var/run:ro \
  --volume=/sys:/sys:ro \
  --volume=/var/lib/docker/:/var/lib/docker:ro \
  --volume=/dev/disk/:/dev/disk:ro \
  --publish=8084:8084 \
  --detach=true \
  --name=cadvisor \
  --privileged \
  --device=/dev/kmsg \
  gcr.io/cadvisor/cadvisor:v0.36.0



 12. grafana and prometheus configuration 
 https://www.devopsart.com/2021/03/step-by-step-to-monitor-docker.html
 https://stefanprodan.com/2016/a-monitoring-solution-for-docker-hosts-containers-and-containerized-services/
 https://medium.com/@piyush.sachdeva055/continous-monitoring-and-alerting-at-docker-host-containers-and-os-level-a40c157f1067

 https://www.metricfire.com/blog/grafana-dashboards-from-basic-to-advanced/

 https://www.metricfire.com/blog/grafana-dashboards-from-basic-to-advanced/

 https://grafana.com/grafana/download?platform=linux

 https://www.techiescorner.in/grafana-mail-alert-configuration/

 https://www.techiescorner.in/grafana-mail-alert-configuration/#comment-33550

 docker run -d --name grafanal -p 3001:3000 -v grafana_config:/etc/grafana -v grafana_data:/var/lib/grafana -v grafana_log:/var/log/grafana grafana/grafana


    docker run -d -p 8084:8080 -v /:/rootfs:ro -v /var/run:/var/run:rw -v /sys:/sys:ro -v /var/lib/docker/:/var/lib/docker:ro --name=cadvisor google/cadvisor:latest

    docker run -d -p 9104:9100 --name=node-exporter prom/node-exporter



    docker run -itd --user 998:998 --name=telegraf \
      -v /proc:/host/proc:ro \
      -v /etc/telegraf/telegraf.conf:/etc/telegraf/telegraf.conf:ro \
      telegraf


docker stats --all --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"

docker stats --format "{{.Container}}: {{.CPUPerc}}"


docker run --rm \
  -e INFLUXDB_DB=telegraf -e INFLUXDB_ADMIN_ENABLED=true \
  -e INFLUXDB_ADMIN_USER=admin \
  -e INFLUXDB_ADMIN_PASSWORD=supersecretpassword \
  -e INFLUXDB_USER=telegraf -e INFLUXDB_USER_PASSWORD=secretpassword \
  -v influxdb-volume:/var/lib/influxdb \
  influxdb /init-influxdb.sh


  SCHEDULE_CLIENT_UPLOAD

   ftp://ftp.50hertz.in/SOLAR/TS/CHELPUR/CHELP_SCCL

13.Sftp command for login into the ftp server

    sshpass -p d@bDy!8&^tyu&{#8 sftp Weather_fb@$14.140.36.68 

    sftp -P 22 Weather_fb@14.140.36.68
    password: 

13.1: How to create user and given setfacl access to the user

Complete FTP Creation on awsftp:
   useradd chel -s /sbin/nologin
   3Orq0PxsQt6lDIAp

   chmod -R 770 CHELPUR

   setfacl -m u:chel:rx /home/wind/
   setfacl -m u:chel:rx /home/wind/SOLAR/
   setfacl -m u:chel:rx /home/wind/SOLAR/TS/
   setfacl -m u:chel:rx /home/wind/SOLAR/TS/CHELPUR/
   setfacl -m u:chel:rx /home/wind/SOLAR/TS/CHELPUR/CHELP_SCCL/

   setfacl -R -m u:chel:rwx /home/wind/SOLAR/TS/CHELPUR/CHELP_SCCL/
   getfacl /home/wind/SOLAR/TS/CHELPUR/
   getfacl /home/wind/SOLAR/TS/CHELPUR/CHELP_SCCL/


Hi Prateek,

Please find the below details of FTP.

Here the details:

Server name:- ftp.50hertz.in
User:chel
Password: 3Orq0PxsQt6lDIAp
Path: ftp://ftp.50hertz.in/SOLAR/TS/CHELPUR/CHELP_SCCL



PSS – Bajariya

State – UP

Generator – Agrawal Solar Power (UP) Pvt. Ltd.

Data provider –     

FTP - ftp://ftp.50hertz.in/SOLAR/UP/BAJARIYA/BAJA_AGAR


User: bajariya

useradd bajariya -s /sbin/nologin
Password: Cg9yqK9UdzIYPdc1
setfacl -m u:bajariya:rx /home/wind/
setfacl -m u:bajariya:rx /home/wind/
setfacl -m u:bajariya:rx /home/wind/SOLAR/
setfacl -m u:bajariya:rx /home/wind/SOLAR/UP/
setfacl -m u:bajariya:rx /home/wind/SOLAR/UP/BAJARIYA/
setfacl -m u:bajariya:rx /home/wind/SOLAR/UP/BAJARIYA/BAJA_AGAR/
setfacl -R -m u:bajariya:rwx /home/wind/SOLAR/UP/BAJARIYA/BAJA_AGAR/
getfacl -R -m u:bajariya:rwx /home/wind/SOLAR/UP/BAJARIYA/BAJA_AGAR/
getfacl  /home/wind/SOLAR/UP/BAJARIYA/BAJA_AGAR/
getfacl  /home/wind/SOLAR/UP/BAJARIYA/


Hi Prateek,

Please find the below details of FTP.

Here the details:

Server name:- ftp.50hertz.in
User:bajariya
Password: Cg9yqK9UdzIYPdc1
Path: ftp://ftp.50hertz.in/SOLAR/UP/BAJARIYA/BAJA_AGAR


14.How to install portainer ?

https://levelup.gitconnected.com/portainer-the-easy-way-to-manage-docker-a982a17146c1


15. how to connect sftp
sftp  -oPort=22 user@ip -p'pwd'


cp Tuticorin_GIREL_SCH20211101_*.csv /tmp/

14. Run cadvisor on 101.53.142.177

docker run -d -p 8084:8080 -v /:/rootfs:ro -v /var/run:/var/run:rw -v /sys:/sys:ro -v /var/lib/docker/:/var/lib/docker:ro --name=cadvisor google/cadvisor:latest

15. Run node-expoter
   
   docker run -d -p 9104:9100 --name=node-exporter prom/node-exporter
 
 Run cadvisor

  docker run -d -p 8084:8080 -v /:/rootfs:ro -v /var/run:/var/run:rw -v /sys:/sys:ro -v /var/lib/docker/:/var/lib/docker:ro --name=cadvisor google/cadvisor:latest

  164.52.195.20
  164.52.195.5
  164.52.195.60
  164.52.202.13
  164.52.202.12 

  164.52.202.17 sftp -P 2202 weather_fb@35.200.207.53

  164.52.202.19 

  164.52.202.33 
  164.52.202.46
  164.52.195.22
  164.52.195.25



  - job_name: 'GAMESHA-FTP-233'

    static_configs:

    - targets: ['101.53.139.233:8084']

      labels:

        alias: 'cadvisor'

  - job_name: 'GAMESHA-FTP-233'

    static_configs:

    - targets: ['101.53.139.233:9104']

      labels:

        alias: 'node-exporter'


        # docker run -d -p 9090:9090 -v /root/config/prometheus.yml:/etc/prometheus/prometheus.yml --name=prometheus prom/prometheus

We can check the targets are up or not in Prometheus by http://server-IP:9090/targets

# docker run -d -p 3000:3000 --name=grafana grafana/grafana:latest

We can access Grafana in browser by http://server-IP:3000

16. Git token:

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

17. How to install Maven on centos7

Download the maven binary file 

wget https://dlcdn.apache.org/maven/maven-3/3.8.3/binaries/apache-maven-3.8.3-bin.zip

Unzip the file 

unzip apache-maven-3.8.3-bin.zip 

cd apache-maven-3.8.3/
mv apache-maven-3.8.3 maven
ln -s /opt/maven/bin/mvn /usr/bin/mvn

Set the Environmental path of maven

vim .bash_profile 

# .bash_profile

# Get the aliases and functions
if [ -f ~/.bashrc ]; then
        . ~/.bashrc
fi

# User specific environment and startup programs
M2_HOME=/opt/maven
M2=$M2_HOME/bin
PATH=$PATH:$HOME/bin:$JAVA_HOME:$M2_HOME:$M2

export PATH
JAVA_HOME=/opt/jdk1.8.0_211/bin/java
JAVA_HOME=/opt/jdk1.8.0_211/

Restart the .bash_profile
source .bash_profile
Check the version:
mvn --version

17. Using maven command create mvn project 

D:\>mvn archetype:generate -DgroupId=com.mkyong.web -DartifactId=java-web-project -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false

test:

D:\>mvn archetype:generate -DgroupId=com.mkyong.web -DartifactId=sample_web_project -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false

18. How to install Jenkins on Docker container
Refer: https://rangle.io/blog/running-jenkins-and-persisting-state-locally-using-docker-2/

docker image pull jenkins/jenkins:lts -- Pull the image form docker hub

docker volume create [your volume name]
    

Run the below command for running jenkins
docker container run -d \
    -p 8083:8080 \
    -v /jenkins_data:/var/jenkins_home \
    --name jenkins-local \
    jenkins/jenkins:lts

~                            
Afte run the container get the code :

go to jenkins container bash

and type the command.

19.Check the backup on 172.16.0.67

cd /DATA/EPM-BKP/
ls -lrth EPM-FTP/ECMWF/source/
ls -lrth /DATA/EPM-BKP/EPM-FTP/IMD/wrf/source/

20. docker compose for maganto

https://cloudkul.com/blog/magento-2-docker-compose/


21.JAVA_HOME Path set up on WINDOWS 

set the system  variable 

JAVA_HOME=C\Programs\java\jdk\
PATH=%JAVA_HOME%\bin

For maven
MAVEN_HOME

ftp://ftp.50hertz.in/SOLAR/AP/Peddapadu/Peddapadu_KBOPL/
User ID: kbopl
PWD:5vUb5tM2YaBcVE3Q

22. Deploy EPM 

1. Download the Parser from the build
2. Login to ssh root@101.53.142.42
3. Check the process
   ps aux |grep SCH
4.Copy the parser to the target server path= /home/www_epm/prod/lib/ 

5.Kill the process and start the parser

kill -9 pid;nohup /opt/jdk1.8.0_211/bin/java -DAsyncLogger.ThreadNameStrategy=UNCACHED -Dserver.mode=qa -Xmx4g -DPROCESSNAME=WEATHER-SCHEDULER -DEPM_HOME=/home/www_epm/prod -Dcom.sel.product=epm -Dspring.batch.job.enabled=false -Dorg.quartz.scheduler.instanceName=WEATHER-SCHEDULER -XX:+HeapDumpOnOutOfMemoryError -jar /home/www_epm/prod/lib/EPM-parser-1.12-SNAPSHOT.jar$

6. Go to the QA server ssh root@101.53.142.177

Restart the parser SCHDULAR-1

23. Project Backup Path Nitin's system

1.we are taken backup of project and thenderbird of all users
2.The backup script is running on 172.16.1.160
3.script location /root/scripts/backup_script/bkp1.sh
4.search the user details on script
5.Check the backup of path 
    df -Th
6.If user change the path , then mention it on script

23. How to take heap Dump on docker container 

1. Go inside the docker container 

 #docker exec -it <contanerid> /bin/bash

2. Inside the container

 See the java process running and take the PID

 #ps -aef| grep java

3. No run the command to create heap dump inside the container

 jmap -dump:live,format=b,file=heap.hprof 1

 list out the heap dump
 #ls -ltrh
 -rw------- 1 root root  19M Nov 27 07:24 heap.hprof

4. Copy the heap dump into local host system

  #docker cp 80e:/usr/local/tomcat/heap.hprof .

  Refer link: https://iceburn.medium.com/thread-and-heap-dumps-in-docker-containers-9aada82226fb


24. Jenkins run the container 

docker run -p 8085:8080 -p 50000:50000 -v myvolume:/tmp/jenkinsworkplace jenkins/jenkins:lts

25. Script add for ftp details

   vim /home/script/archive-sync/FTP-Sync-Archive.sh
   vim /home/script/archive-sync/solar-sync.txt
   vim /home/script/archive-sync/FTP-Arc-Archive.sh
   vim /home/script/archive-sync/solar-arch.txt
   vim /home/script/archive-sync/ArchiveS3.sh

    ftp://ftp.50hertz.in/SOLAR/GJ/OCHHAN/OCHH_ANUP1
          ftp://ftp.50hertz.in/SOLAR/GJ/OCHHAN/OCHH_ANUP2
          ftp://ftp.50hertz.in/SOLAR/GJ/OCHHAN/OCHH_ANUP3


PSS – Khandke

State – MH

Generator – Energy Bot

Data provider – Energy Bot

FTP - ftp://ftp.50hertz.in/WIND/PCN01_METER


user: enbot
pwd : DblCPUVo78QKuWK0



Hi Prateek,

Please find the below details of FTP.

Here the details:

Server name:- ftp.50hertz.in
User:enbot
Password: DblCPUVo78QKuWK0
Path: ftp://ftp.50hertz.in/WIND/PCN01_METER


/home/script/archive-sync/wind-sync2.txt

/home/script/archive-sync/wind-sync1.txt


kill -9 15614; nohup java -jar wind-power-prediction.jar&



d@bDy!8&^tyu&{#8

awk -F: '{ print $1}' /etc/passwd


26. Production Deployment on EPM application

1. Go to Jenkins "https://ci.50hertz.in/view/EPM/job/epm/job/master/"

2. Trigger the build "Build now" and take download the "EPM-parser-1.12-SNAPSHOT.jar"
3.copy to the EPM production server 35.154.19.217 
4.Now copy "EPM-parser-1.12-SNAPSHOT.jar" from /tmp folder to /home/www_epm/prod/lib/
5.Rename the parser as per the dateswise
mv EPM-parser-1.12-SNAPSHOT.jar EPM-parser-1.12-SNAPSHOT_131220201_1534.jar
6. Inside the script change the file name 
 # crontab -l
 # vim /home/www_epm/prod/bin/EPM-weather-engine.sh

7. Check the status for parser and restart it.

# ps -aux | grep weather
#kill -9 1488; sh /home/www_epm/prod/bin/EPM-weather-engine.sh

8.Now check the process

ps -ef | grep WEATHER

If it is running fine, then parser have deployed.


"Env": [
                "PATH=/usr/share/grafana/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                "GF_PATHS_CONFIG=/etc/grafana/grafana.ini",
                "GF_PATHS_DATA=/var/lib/grafana",
                "GF_PATHS_HOME=/usr/share/grafana",
                "GF_PATHS_LOGS=/var/log/grafana",
                "GF_PATHS_PLUGINS=/var/lib/grafana/plugins",
                "GF_PATHS_PROVISIONING=/etc/grafana/provisioning"
            ],


docker run -itd -p 3000:3000 –name grafana -e “GF_SMTP_ENABLED=true” -e “GF_SMTP_HOST=auto.monitoring@50hertz.in” -e “GF_SMTP_USER=auto.monitoring” -e “GF_SMTP_PASSWORD=#$%^Hertz$@M” grafana/grafana:latest


docker run    d\ -
   p 3000: 3000\
   --name grafana\ -
   e "GF_SMTP_ENABLED=true"\ -
   e "GF_SMTP_HOST=auto.monitoring@50hertz.in"\ -
   e "GF_SMTP_USER=auto.monitoring"\ -
   e "GF_SMTP_PASSWORD=#$%^Hertz$@M"\
grafana / grafana: 5.1 .0

To change the time on command line:

timedatectl set-time 14:50:20


Procedure

    Stop the container(s) using the following command:

    docker-compose down

    Delete all containers using the following command:

    docker rm -f $(docker ps -a -q)

    Delete all volumes using the following command:

    docker volume rm $(docker volume ls -q)

    Restart the containers using the following command:

    docker-compose up -d

    docker-compose -f docker-compose.yml restart grafana


    influx user create -n hertz -p PaSsWoRd

    CREATE USER hertz50 WITH PASSWORD 'admin123'


    CREATE USER hertz50 WITH PASSWORD 'admin123' WITH ALL PRIVILEGES


27.https://docs.cpanel.net/knowledge-base/sql/how-to-enable-the-slow-query-log-in-mysql-or-mariadb/

This is slow query

28. HEA production deployment

1. For Hea production deployment , login to the 13.126.148.5

    #ssh ec2-user@13.126.148.5
2. Go to the deployment path
    #cd $HEA_HOME/lib
    #pwd
    /home/www_epm/hea/lib
3. Check the process for take the process id of it
    ps aux | grep SCH

    e.g.

    root     20608  7.0  6.4 5936712 1026340 ?     Sl   12:02   2:06 /var/lib/java/jdk1.8.0_211/bin/java -Xmx1500M -Dserver.mode=prod -Xmx2g -DHEA_HOME=/home/www_epm/hea -Dcom.sel.product=hea -DPROCESSNAME=HEA-SCHEDULAR -Dspring.batch.job.enabled=false -Dorg.quartz.scheduler.instanceName=HEA-SCHEDULAR -XX:+HeapDumpOnOutOfMemoryError -jar /home/www_epm/hea/lib/HEA_DATA_SYNC_ENGINE-1.2-SNAPSHOT.jar

    Kill the process

    kill -9 20608

4. See the file in this folder
   # ls -ltrh

   HEA_DATA_SYNC_ENGINE-1.2-SNAPSHOT.jar
5. Take a Backup of this above

   # mv HEA_DATA_SYNC_ENGINE-1.2-SNAPSHOT.jar HEA_DATA_SYNC_ENGINE-1.2-SNAPSHOT.jar_20122021_1201

6. Move the latest artifact into this current folder(/home/www_epm/hea/lib) from /tmp directory

   mv /tmp/HEA_DATA_SYNC_ENGINE-1.2-SNAPSHOT.jar .

7. Now run the script for HEA_DATA_SYNC_ENGINE

   sh /home/www_epm/hea/bin/HEA-engine.sh

Note:

Suppose the Depolyment has version, then we need to change the version of script before runnig it.

X8eoorq.XtB5

sudo mysql_secure_installation -p 'X8eoorq.XtB5'

Admin@1212

 grant all privileges on test.* to root@localhost identified by 'Admin@1212';

To take a backup of mysql (export)
 #mysqldump -uroot -pAdmin@1212 hea  | gzip -c > hea_28122021.sql.gz
To import the mysql databases:
1.Create database Schema e.g. hea (CREATE DATABASE hea;)

#CREATE DATABASE hea;

 gunzip -c hea_28122021.sql.gz | mysql -uroot -pAdmin@1212 hea&
Rohan@1212




docker run -d --name grafanal -p 3001:3000 -v grafana_config:/etc/grafana -v grafana_data:/var/lib/grafana -v grafana_log:/var/log/grafana grafana/grafana


node_load1{instance=~"$node"}


29. Check the Backup Data on 13.126.148.5

 Path: /EPMDATA/Weather/Weather-Backup

drwxr-xr-x 3 www_epm www_epm 4.0K Jul 20  2019 GETCO --previous date data(28th)
drwxrwx--- 7 root    root    4.0K Aug 27  2020 ECMWF --previous date data(28th)
drwxr-xr-x 3 root    root    4.0K Aug 30 14:05 ERA --previous date data(28th)
drwxr-xr-x 3 root    root    4.0K Sep  1 09:01 IMD_ALL_INDIA -- previous date data(27th date data)
drwxr-xr-x 3 root    root    4.0K Sep  1 10:10 RAIN_OBSERVED -- Previous date (28th)

netstat -tn 2>/dev/null | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -nr | head

awk '{print $7" - ",$14}' xferlog | sort -nr | head




Client – Salasar Green energy pvt ltd

PSS – Sarila

State – UP

W/S – Solar

Path - ftp://ftp.50hertz.in/SOLAR/UP/SARILA/SALA_SARI

useradd sarila -s /sbin/nologin


AfX7M9XAYBCmbtMk



   chmod -R 770 CHELPUR

   setfacl -m u:sarila:rx /home/wind/
   setfacl -m u:sarila:rx /home/wind/SOLAR/
   setfacl -m u:sarila:rx /home/wind/SOLAR/UP/
   setfacl -m u:sarila:rx /home/wind/SOLAR/UP/SARILA/
   setfacl -m u:sarila:rx /home/wind/SOLAR/UP/SARILA/SALA_SARI

   setfacl -R -m u:sarila:rwx /home/wind/SOLAR/UP/SARILA/SALA_SARI

   setfacl -R -m u:kafka:rx SARALA/ 
   

Hi Prateek,

Please find the below details of FTP.

Here the details:

Server name:- ftp.50hertz.in
User:sarila
Password: AfX7M9XAYBCmbtMk
Path: ftp://ftp.50hertz.in/SOLAR/UP/SARILA/SALA_SARI

vim /home/script/archive-sync/FTP-Sync-Archive.sh
vim /home/script/archive-sync/solar-sync.txt

vim /home/script/archive-sync/solar-arch.txt


rsync -avz root@101.53.156.195:/home/kafka/*  /DATA/Server_Config-Project_Name/ASSET/KAFKA_C1_ASSET/kafaka_`date +%m.%d.%Y`


Discussion For Infra Security,Database Access Policy, Server Hardware Sizing


.177
.42
.49
52
ip
dockw


cd /home/DEPLOY/SOLAR/CURRENT/

vim opc-batch.jar


 cd /home/NVKN_HOME/conf

 vim nvkn.properties


 cd /home/DEPLOY/SOLAR/CURRENT/
 vim nvkn.properties
 vim re.properties 
 

















